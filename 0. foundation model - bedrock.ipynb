{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d72307",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Fundamental\n",
    "\n",
    "이 노트북은, SageMaker Notebook conda_python3 커널에서 테스트 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c524d",
   "metadata": {},
   "source": [
    "## 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들을 이 환경에 설치합니다.\n",
    "\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19569358",
   "metadata": {},
   "source": [
    "# 1. Bedrock Embedding 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea761946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Bedrock 임베딩 가져오는 함수\n",
    "def get_embedding(text):\n",
    "    session = boto3.Session()\n",
    "    bedrock = session.client(service_name='bedrock-runtime')\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=json.dumps({\n",
    "            \"inputText\": text,\n",
    "            \"dimensions\": 1024\n",
    "        }),\n",
    "        modelId=\"amazon.titan-embed-text-v2:0\", # Titan Text Embeddings V2\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body['embedding']\n",
    "\n",
    "\n",
    "# 코사인 유사도 계산 함수\n",
    "def calculate_similarity(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c38028-2efd-4c27-b997-96a866c9dd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 테스트 문장\n",
    "test_sentence = \"인공지능은 현대 기술의 핵심 분야입니다.\"\n",
    "test_embedding = get_embedding(test_sentence)\n",
    "\n",
    "compare_sentences = [\n",
    "    \"축구는 전 세계에서 가장 인기 있는 스포츠 중 하나입니다.\",\n",
    "    \"클래식 음악은 많은 사람들에게 평화를 줍니다.\",\n",
    "    \"AI는 오늘날 기술 혁신의 중심에 있습니다.\",\n",
    "    \"현대 기술에서 인공지능의 역할은 매우 중요합니다.\",\n",
    "    \"고대 이집트의 피라미드는 건축학적 경이로움입니다.\",\n",
    "    \"머신러닝은 현대 기술 발전의 주요 동력입니다.\",\n",
    "    \"지구 온난화는 현대 사회의 심각한 환경 문제입니다.\",\n",
    "    \"건강한 식단은 장수의 비결 중 하나입니다.\",\n",
    "    \"바다에는 아직 발견되지 않은 많은 생물 종이 있습니다.\"\n",
    "]\n",
    "\n",
    "compare_results = []\n",
    "for compare_sentence in compare_sentences:\n",
    "    compare_embedding = get_embedding(compare_sentence)\n",
    "    similarity = calculate_similarity(test_embedding, compare_embedding)\n",
    "    compare_results.append((compare_sentence, similarity))\n",
    "\n",
    "# 유사도를 기준으로 내림차순 정렬\n",
    "compare_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"# 테스트 문장\")\n",
    "print(f\"\\\"{test_sentence}\\\"\")\n",
    "\n",
    "print(\"\\n# 임베딩 비교 결과 (유사도 높은 순)\")\n",
    "for i, (sentence, similarity) in enumerate(compare_results, 1):\n",
    "    print(f\"{i}. 유사도: {similarity:.4f} - \\\"{sentence}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d353500",
   "metadata": {},
   "source": [
    "# 2. Bedrock Claude 3 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f3de0",
   "metadata": {},
   "source": [
    "## 2-1. 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrock 클라이언트 생성\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Claude 3 Haiku 모델 ID\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# 시스템 프롬프트 설정\n",
    "system = [{\"text\": \"당신은 친절한 AI 친구입니다. 상냥하게 답변해주세요.\"}]\n",
    "\n",
    "# 대화 메시지 설정\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": \"안녕하세요, 당신은 누구인가요?\"}]}\n",
    "]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "inference_config={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\n",
    " \n",
    "# converse API 호출\n",
    "try:\n",
    "    response = bedrock_runtime.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    \n",
    "    # 응답 처리\n",
    "    ai_message = response[\"output\"][\"message\"]\n",
    "    output_text = ai_message[\"content\"][0][\"text\"]\n",
    "    print(\"# Claude 3 Haiku의 응답\")\n",
    "    print(f\"- {output_text}\")\n",
    "    print()\n",
    "        \n",
    "    \n",
    "    # 토큰 사용량 출력\n",
    "    token_usage = response[\"usage\"]\n",
    "    print(\"# 토큰 사용량\")\n",
    "    print(f\"- 입력 토큰: {token_usage['inputTokens']}\")\n",
    "    print(f\"- 출력 토큰: {token_usage['outputTokens']}\")\n",
    "    print(f\"- 총 토큰: {token_usage['totalTokens']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0203236",
   "metadata": {},
   "source": [
    "## 2-2. 텍스트 생성 - 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Bedrock 클라이언트 생성\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Claude 3 Haiku 모델 ID\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# 시스템 프롬프트 설정\n",
    "system = [{\"text\": \"당신은 친절한 AI 친구입니다. 상냥하게 답변해주세요.\"}]\n",
    "\n",
    "# 대화 메시지 설정\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": \"안녕하세요, 당신은 누구인가요?\"}]}\n",
    "]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "inference_config={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9}\n",
    " \n",
    "# converse API 호출\n",
    "try:\n",
    "    response = bedrock_runtime.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    \n",
    "    # 스트리밍 응답 처리\n",
    "    print(\"# AI 응답\\n-\", end=\" \", flush=True)\n",
    "    for event in response['stream']:\n",
    "        if 'contentBlockDelta' in event:\n",
    "            content_delta = event['contentBlockDelta']\n",
    "            if 'delta' in content_delta and 'text' in content_delta['delta']:\n",
    "                print(content_delta['delta']['text'], end=\"\", flush=True)\n",
    "        elif 'messageStop' in event:\n",
    "            print()\n",
    "            pass\n",
    "        elif 'metadata' in event:\n",
    "            metadata = event['metadata']\n",
    "            if 'usage' in metadata:\n",
    "                # 토큰 사용량 출력\n",
    "                print(\"\\n# 토큰 사용량\")\n",
    "                print(f\"- 입력 토큰: {metadata['usage']['inputTokens']}\")\n",
    "                print(f\"- 출력 토큰: {metadata['usage']['outputTokens']}\")\n",
    "                print(f\"- 총 토큰: {metadata['usage']['totalTokens']}\")\n",
    "                print()\n",
    "            if 'metrics' in event['metadata']:\n",
    "                print(\n",
    "                    f\"# Latency\\n- {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476a624",
   "metadata": {},
   "source": [
    "## 2-3. 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Bedrock 클라이언트 생성\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Claude 3 Haiku 모델 ID\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = \"image/sample_image_camping.jpeg\"\n",
    "\n",
    "# 이미지 표시\n",
    "display(Image(filename=image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 리드\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    encoded_image = image_file.read()\n",
    "\n",
    "# 대화 메시지 설정\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": \"jpeg\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": encoded_image\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\"text\": \"이 이미지에 대해 자세히 설명해주세요.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "inference_config = {\"temperature\": 0.5, \"topP\": 0.9}\n",
    "\n",
    "# converse API 호출\n",
    "try:\n",
    "    response = bedrock_runtime.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        inferenceConfig=inference_config,\n",
    "    )\n",
    "    \n",
    "    # 응답 처리\n",
    "    ai_message = response[\"output\"][\"message\"]\n",
    "    output_text = ai_message[\"content\"][0][\"text\"]\n",
    "    print(\"Claude 3 Haiku의 이미지 분석 결과:\")\n",
    "    print(output_text)\n",
    "    \n",
    "    # 토큰 사용량 출력\n",
    "    token_usage = response[\"usage\"]\n",
    "    print(f\"\\n입력 토큰: {token_usage['inputTokens']}\")\n",
    "    print(f\"출력 토큰: {token_usage['outputTokens']}\")\n",
    "    print(f\"총 토큰: {token_usage['totalTokens']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd863209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
