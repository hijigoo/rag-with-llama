{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1478cd-d2f1-4e86-ab1f-7d68ec3aa194",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint - huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeabf9f-9198-4874-961e-0cd37e6196db",
   "metadata": {},
   "source": [
    "## 0. SageMaker Endpoint 에 HuggingFace model 배포하기 (5분 소요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4354e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_HUB_TOKEN=\"[YOUR TOKEN]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734d108-d509-47a8-94db-ae2765b2d414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'meta-llama/Llama-3.2-1B-Instruct',\n",
    "    'SM_NUM_GPUS': json.dumps(1),\n",
    "    'HUGGING_FACE_HUB_TOKEN': HUGGING_FACE_HUB_TOKEN\n",
    "}\n",
    "\n",
    "assert hub['HUGGING_FACE_HUB_TOKEN'] != '<REPLACE WITH YOUR TOKEN>', \"You have to provide a token.\"\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"2.2.0\"),\n",
    "    env=hub,\n",
    "    role=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    container_startup_health_check_timeout=300,\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "    \"inputs\": \"Hey my name is Julien! How are you?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58908b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3bb7b-5679-442b-9c8e-020a36afbaf4",
   "metadata": {},
   "source": [
    "## 1. boto3 를 이용해서 SageMaker Endpoint 에 배포된 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747a463-fabc-4cc2-97ee-b6bcdc303a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import datetime\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_runtime = boto3.client(\n",
    "    \"sagemaker-runtime\",\n",
    "    region_name=region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab9388-91ed-4db3-8379-3d0b00c350e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client(\"sagemaker-runtime\", region_name='us-west-2')\n",
    "\n",
    "system =\"You are a helpful assistant\" \n",
    "text = \"Hello! Who are you?\"\n",
    "prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{system}|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 128,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.9,\n",
    "        \"return_full_text\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "time_to_first_token = -1\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "#    EndpointName=\"huggingface-pytorch-tgi-inference-2024-11-20-16-08-14-985\",\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload),\n",
    ")\n",
    "\n",
    "# 응답 처리\n",
    "end_time = datetime.datetime.now()\n",
    "response_body = json.loads(response['Body'].read().decode())\n",
    "\n",
    "# 응답 시간 계산\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"# System\\n- {system}\\n\")\n",
    "print(f\"# Text\\n- {text}\\n\")\n",
    "print(f\"# Prompt\\n- {prompt}\")\n",
    "print(f\"# Response\\n- \" + response_body[0][\"generated_text\"] + \"\\n\")\n",
    "print(f\"# Total time\\n- {total_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a353ea",
   "metadata": {},
   "source": [
    "## 2. SageMaker Endpoint 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32b597-0cad-480d-b12b-9b557a2eba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
